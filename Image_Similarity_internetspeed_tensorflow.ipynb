{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQnFfe_2pG4S"
   },
   "source": [
    "### Importing Required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yN9yirdLnz6d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pickle\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "import glob\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxZ73Ltmnz6e"
   },
   "source": [
    "### Loading the Resnet50 model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "szd72V3drLCX",
    "outputId": "f33c2f32-3354-4bbf-c6be-9ce6bd83c488"
   },
   "outputs": [],
   "source": [
    "model = ResNet50(weights='imagenet',\n",
    "                         include_top=False,\n",
    "                         input_shape=(224, 224, 3),\n",
    "                        pooling='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VW9fyJKjyEcH",
    "outputId": "2c86b581-f3b5-4f45-d195-f530f9a683b8"
   },
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "za5aAGhgnz6g"
   },
   "source": [
    "\n",
    "\n",
    "## Feature Extraction :\n",
    "\n",
    "Let's define a function to extract image features given an image and a model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Fc9vtRenz6g"
   },
   "outputs": [],
   "source": [
    "def extract_features(img_path, model):\n",
    "    input_shape = (224, 224, 3)\n",
    "    img = image.load_img(img_path,target_size=(input_shape[0], input_shape[1]))\n",
    "    img_array = image.img_to_array(img)\n",
    "    expanded_img_array = np.expand_dims(img_array, axis=0)\n",
    "    preprocessed_img = preprocess_input(expanded_img_array)\n",
    "    #extracting feature from model\n",
    "    features = model.predict(preprocessed_img)\n",
    "    flattened_features = features.flatten()\n",
    "    normalized_features = flattened_features / norm(flattened_features)\n",
    "    return normalized_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57uKAEMxnz6h"
   },
   "source": [
    "Let's see the feature length the model generates by running on an example image. If you don't have the usual cat image available locally, let's download it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_USxAyninz6h",
    "outputId": "4668ee3e-e43c-4088-b79d-7fcb5715ae16"
   },
   "outputs": [],
   "source": [
    "features = extract_features(IMG_PATH, model)\n",
    "print(\"Total length of features for one image: \", len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rs8nZZCLnz6i",
    "outputId": "0137b3a8-2cde-43b9-f2d5-8117c55bef32"
   },
   "outputs": [],
   "source": [
    "%timeit features = extract_features(IMG_PATH, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "esrDlqWa9sGo"
   },
   "source": [
    "## Benchmarking time taken to extract features over the entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8jELqglInz6i"
   },
   "source": [
    "The time taken to extract features is dependent on a few factors such as image size, computing power etc.\n",
    "\n",
    "A better benchmark would be running the network over an entire dataset. \n",
    "\n",
    "A simple change to the existing code will allow this.\n",
    "\n",
    "Let's make a handy function to recursively get all the image files under a root directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "biSAC49dnz6j"
   },
   "outputs": [],
   "source": [
    "extensions = ['.jpg', '.JPG', '.jpeg', '.JPEG', '.png', '.PNG']\n",
    "\n",
    "def get_file_list(root_dir):\n",
    "    file_list = []\n",
    "    for root, directories, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if any(ext in filename for ext in extensions):\n",
    "                filepath = os.path.join(root, filename)\n",
    "                if os.path.exists(filepath):\n",
    "                    file_list.append(filepath)\n",
    "                else:\n",
    "                    print(filepath)\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HtebW5cnz6j"
   },
   "source": [
    "Now, let's run the extraction over the entire dataset and time it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XC75Z2Dau77Z",
    "outputId": "e2a53cff-e243-4bb1-f603-89fc50663c6e"
   },
   "outputs": [],
   "source": [
    "# path to the your datasets\n",
    "root_dir = r'D:\\tensorflow\\101_ObjectCategories\\101_ObjectCategories'\n",
    "filenames = sorted(get_file_list(root_dir))\n",
    "print(len(filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3m9zvr5ryqU2"
   },
   "source": [
    "Now, let's run the extraction over the entire dataset and time it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qLFm-fUDFk2Z",
    "outputId": "88aba172-1056-4a12-981a-799b71577d72"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "generator = tf.keras.utils.image_dataset_from_directory(root_dir,\n",
    "                                            shuffle=False,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                            image_size=(224,224))\n",
    "\n",
    "num_images = len(generator.file_paths)\n",
    "num_epochs = int(math.ceil(num_images / BATCH_SIZE))\n",
    "\n",
    "start_time = time.time()\n",
    "feature_list = []\n",
    "feature_list = model.predict(generator, num_epochs)\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d diimensional representation took about 16 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EhpUGDH8Jd8M",
    "outputId": "7cff62b7-1918-482d-d599-075b91de6f76"
   },
   "outputs": [],
   "source": [
    "for i, features in enumerate(feature_list):\n",
    "    feature_list[i] = features / norm(features)\n",
    "\n",
    "feature_list = feature_list.reshape(len(feature_list), -1)\n",
    "\n",
    "print(\"Num images   = \", len(generator.file_paths))\n",
    "print(\"Shape of feature_list = \", feature_list.shape)\n",
    "print(\"Time taken in min = \", (end_time - start_time)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJ9xPhBc7uGG"
   },
   "source": [
    "By now, we have generated features from the entire dataset of images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0h25HAoXnz6l"
   },
   "source": [
    "With the benchmarking experiments squared away, let's save the features as intermediate files to use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(generator.class_names, open(r'C:\\Users\\ChethanNingappa\\Downloads\\experiment\\class_names.txt','wb'))\n",
    "pickle.dump(generator.file_paths, open(r'C:\\Users\\ChethanNingappa\\Downloads\\experiment\\file_paths.txt', 'wb'))\n",
    "pickle.dump(feature_list,open(r'C:\\Users\\ChethanNingappa\\Downloads\\experiment\\resnet50' + '.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8B8_2fYIVlV"
   },
   "source": [
    "That’s all folks! We’re done with the feature extraction part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGW5JDLqzLZG"
   },
   "source": [
    "## Similarity Search:\n",
    "- Given a QUERY image, our aim is to find another photo in our dataset similar to the current one. \n",
    "\n",
    "- We begin by loading the precomputed features:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = pickle.load(open(r'C:\\Users\\ChethanNingappa\\Downloads\\experiment\\file_paths.txt', 'rb'))\n",
    "feature_list = pickle.load(open(r\"C:\\Users\\ChethanNingappa\\Downloads\\experiment\\resnet50.pickle\",'rb'))\n",
    "class_ids = pickle.load(open(r'C:\\Users\\ChethanNingappa\\Downloads\\experiment\\class_names.txt', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZUnMMFb2fDHn",
    "outputId": "4d60875d-3900-4584-d98d-1372b264482e"
   },
   "outputs": [],
   "source": [
    "num_images = len(filenames)\n",
    "num_features_per_image = len(feature_list[0])\n",
    "print(\"Number of images = \", num_images)\n",
    "print(\"Number of features per image = \", num_features_per_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "768Jq4mKFVKy",
    "outputId": "767521c3-5359-48e4-ce5e-1e20147417c0"
   },
   "outputs": [],
   "source": [
    "feature_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BwaNXcYxdkzS",
    "outputId": "b4ab814d-b8cc-44c4-bca7-7e171bec8451"
   },
   "outputs": [],
   "source": [
    "len(class_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixcvKAUDzles"
   },
   "source": [
    "## How we find similar images after feature extraction ?\n",
    "\n",
    "Using Knearest Neighbors :  \n",
    "- We’ll use Python’s machine learning library scikit-learn for\n",
    "finding nearest neighbors of the query features; that is, features that represent a query image. \n",
    "\n",
    "- We train a nearest-neighbor model using the brute-force algorithm to find the nearest five neighbors based on Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vgDbY_nmQRJx"
   },
   "outputs": [],
   "source": [
    "random_index = random.randint(0, num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G-C-cXhVuhSJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "neighbors = NearestNeighbors(n_neighbors=5, algorithm='brute', metric='euclidean').fit(feature_list)\n",
    "distances, indices = neighbors.kneighbors([feature_list[random_index]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uQ3HLyWeChJw"
   },
   "source": [
    "Now, let's look at the time it takes to search for the nearest neighbors for the selected random image using the trained model with the Brute force algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QEBEQeHLHKlT",
    "outputId": "9d0a1a8d-3f23-4b92-c11a-0eaacb04d20d"
   },
   "outputs": [],
   "source": [
    "%timeit distances, indices = neighbors.kneighbors([feature_list[random_index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "id": "AyXeSspKCkl7",
    "outputId": "80a27876-1957-4254-ccf6-9c7bed98db88"
   },
   "outputs": [],
   "source": [
    "plt.imshow(mpimg.imread(filenames[random_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "id": "FGl_NYoKfYim",
    "outputId": "35444606-06f9-42de-ea0a-ef7294844f5e"
   },
   "outputs": [],
   "source": [
    "plt.imshow(mpimg.imread(filenames[indices[0][0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "subQ8f_LfboU",
    "outputId": "1d88c253-de6f-44a4-9890-cd746a608ed8"
   },
   "outputs": [],
   "source": [
    "plt.imshow(mpimg.imread(filenames[indices[0][1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "iyf9tnwP9glj",
    "outputId": "efb1531f-fb52-45c0-f40e-1f25141dfdea"
   },
   "outputs": [],
   "source": [
    "plt.imshow(mpimg.imread(filenames[indices[0][2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x1yR7VrmfeZQ",
    "outputId": "bbf11096-f447-47ad-e77c-9b4f0dc33019"
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(distances[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PVgQOLBSfjPA"
   },
   "outputs": [],
   "source": [
    "# Helper function to get the classname\n",
    "def classname(str):\n",
    "    return str.split('\\\\')[-2]\n",
    "\n",
    "\n",
    "# Helper function to get the classname and filename\n",
    "def classname_filename(str):\n",
    "    return str.split('\\\\')[-2] + '\\\\' + str.split('\\\\')[-1]\n",
    "\n",
    "\n",
    "# Helper functions to plot the nearest images given a query image\n",
    "def plot_images(filenames, distances):\n",
    "    images = []\n",
    "    for filename in filenames:\n",
    "        images.append(mpimg.imread(filename))\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    columns = 4\n",
    "    for i, image in enumerate(images):\n",
    "        ax = plt.subplot(len(images) // columns + 1, columns, i + 1)\n",
    "        if i == 0:\n",
    "            ax.set_title(\"Query Image\\n\" + classname_filename(filenames[i]))\n",
    "        else:\n",
    "            ax.set_title(\"Similar Image\\n\" + classname_filename(filenames[i]) +\n",
    "                         \"\\nDistance: \" +\n",
    "                         str(float(\"{0:.2f}\".format(distances[i]))))\n",
    "        plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SgiJW48lfmRZ",
    "outputId": "4890a253-db31-4916-92ff-f043784d59f3"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    random_image_index = random.randint(0, 8000)\n",
    "    distances, indices = neighbors.kneighbors([feature_list[random_image_index]])\n",
    "    \n",
    "    # Don't take the first closest image as it will be the same image\n",
    "    similar_image_paths = [filenames[random_image_index]] + \\\n",
    "        [filenames[indices[0][i]] for i in range(1, 4)]\n",
    "#print(similar_image_paths)\n",
    "    plot_images(similar_image_paths, distances[0].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mzS7UI3vfwfe",
    "outputId": "8acf83f7-39a1-4817-bc8a-e6f1816ed963"
   },
   "outputs": [],
   "source": [
    "# Calculating some stats\n",
    "print(\"Median distance between all photos: \", np.median(distances))\n",
    "print(\"Max distance between all photos: \", np.max(distances))\n",
    "print(\"Median distance among most similar photos: \",np.median(distances[:, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qt_5nUPLUjZ"
   },
   "source": [
    "### Calculating Accuracy of the Brute Force Model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GaFmLPbDLcGE"
   },
   "outputs": [],
   "source": [
    "# Helper function that calculates accuracy using the nearest neighbors brute force algorithm\n",
    "def calculate_accuracy(feature_list):\n",
    "    num_nearest_neighbors = 5\n",
    "    correct_prediction = 0\n",
    "    incorrect_prediction = 0\n",
    "    neighbors = NearestNeighbors(n_neighbors=num_nearest_neighbors,algorithm='brute',metric='euclidean').fit(feature_list)\n",
    "    start = time.time()\n",
    "    for i in range(len(feature_list)):\n",
    "        distances, indices = neighbors.kneighbors([feature_list[i]])\n",
    "        for j in range(1, num_nearest_neighbors):\n",
    "            if (classname(filenames[i]) == classname(filenames[indices[0][j]])):\n",
    "                correct_prediction += 1\n",
    "            else:\n",
    "                incorrect_prediction += 1\n",
    "    end = time.time()\n",
    "    accuracy = round(100.0 * correct_prediction /\n",
    "        (1.0 * correct_prediction + incorrect_prediction), 2), end - start\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lcevDdp4JyXL",
    "outputId": "26ae5cd7-8341-419d-e387-84996b5528e3"
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy on original feature set : \",calculate_accuracy(feature_list[:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-4oaDlGgwgHi"
   },
   "source": [
    "## Visualizing Image Clusters with t-SNE:\n",
    "\n",
    "Let’s step up the game by visualizing the entire dataset!\n",
    "\n",
    "- To do this, we need to reduce the dimensions of the feature vectors because it’s not possible to plot a 2,048-dimension vector (the feature-length) in two dimensions (the paper).\n",
    "- The t-distributed stochastic neighbor embedding (t-SNE) algorithm reduces the high-dimensional feature vector to 2D, providing a bird’s-eye view of the dataset, which is helpful in recognizing clusters and nearby images. \n",
    "- t-SNE is difficult to scale to large datasets, so it is a good idea to reduce the dimensionality using Principal Component Analysis (PCA) and then call t-SNE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cvoFZoaFSQdz"
   },
   "outputs": [],
   "source": [
    "# Perform PCA over the features\n",
    "num_feature_dimensions=150 # Set the number of features \n",
    "pca = PCA(n_components = num_feature_dimensions)\n",
    "pca.fit(feature_list)\n",
    "feature_list_compressed = pca.transform(feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4obv71dhQ5eL"
   },
   "source": [
    "Time taken to search similar images for one image using PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-sbINIm7PsJ0",
    "outputId": "dc678622-11f3-4be6-c71a-3d07145da0a7"
   },
   "outputs": [],
   "source": [
    "neighbors = NearestNeighbors(n_neighbors=5, algorithm='brute', metric='euclidean').fit(feature_list_compressed)\n",
    "distances, indices = neighbors.kneighbors([feature_list_compressed[random_index]])\n",
    "%timeit distances, indices = neighbors.kneighbors([feature_list_compressed[random_index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "id": "lP0R6vt2wwhn",
    "outputId": "61ed53e0-0c25-4e93-9204-966a60cfb9c7"
   },
   "outputs": [],
   "source": [
    "# For speed and clarity, we'll analyze about first half of the dataset.\n",
    "selected_features = feature_list_compressed[:4000]\n",
    "selected_class_ids = class_ids[:4000]\n",
    "selected_filenames = filenames[:4000]\n",
    "tsne_results = TSNE(n_components=2,verbose=1,metric='euclidean').fit_transform(selected_features)\n",
    "# Plot a scatter plot from the generated t-SNE results\n",
    "colormap = plt.cm.get_cmap('coolwarm')\n",
    "scatter_plot = plt.scatter(tsne_results[:,0],tsne_results[:,1],c=None, cmap=colormap)\n",
    "plt.colorbar(scatter_plot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6z6x4nwjD10w"
   },
   "outputs": [],
   "source": [
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from matplotlib.cbook import get_sample_data\n",
    "\n",
    "\n",
    "def plot_images_in_2d(x, y, image_paths, axis=None, zoom=1):\n",
    "    if axis is None:\n",
    "        axis = plt.gca()\n",
    "    x, y = np.atleast_1d(x, y)\n",
    "    for x0, y0, image_path in zip(x, y, image_paths):\n",
    "        image = Image.open(image_path)\n",
    "        image.thumbnail((100, 100), Image.ANTIALIAS)\n",
    "        img = OffsetImage(image, zoom=zoom)\n",
    "        anno_box = AnnotationBbox(img, (x0, y0),xycoords='data',frameon=False)\n",
    "        axis.add_artist(anno_box)\n",
    "    axis.update_datalim(np.column_stack([x, y]))\n",
    "    axis.autoscale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eW_kRROvD52n"
   },
   "outputs": [],
   "source": [
    "def show_tsne(x, y, selected_filenames):\n",
    "    fig, axis = plt.subplots()\n",
    "    fig.set_size_inches(22, 22, forward=True)\n",
    "    plot_images_in_2d(x, y, selected_filenames, zoom=0.3, axis=axis)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sJ9BaeIQD8R4",
    "outputId": "07c14df1-db2b-4661-e4d0-ff43e50125e1"
   },
   "outputs": [],
   "source": [
    "show_tsne(tsne_results[:, 0], tsne_results[:, 1], selected_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRFRNDra1WHN"
   },
   "source": [
    "\n",
    "Neat! There is a clearly demarcated cluster of human faces, flowers, vintage cars, ships, bikes, and a somewhat spread-out cluster of land and marine animals. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2CKRDflQmfp"
   },
   "source": [
    "## Accuracy of Brute Force over the PCA compressed Caltech101 features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7FWCLixLSgCS",
    "outputId": "2298dde4-7245-40bc-83e5-995c54969bc3"
   },
   "outputs": [],
   "source": [
    "pca_dimensions = [1, 2, 3, 4, 5, 10, 20, 50, 75, 100, 150, 200]\n",
    "pca_accuracy = []\n",
    "pca_time = []\n",
    "\n",
    "for dimensions in pca_dimensions:\n",
    "    pca = PCA(n_components=dimensions)\n",
    "    pca.fit(feature_list)\n",
    "    feature_list_compressed = pca.transform(feature_list[:])\n",
    "    # Calculate accuracy over the compressed features\n",
    "    accuracy, t = calculate_accuracy(feature_list_compressed[:])\n",
    "    pca_time.append(t)\n",
    "    pca_accuracy.append(accuracy)\n",
    "    print(\"For PCA Dimensions = \", dimensions, \",\\tAccuracy = \", accuracy, \"%\",\n",
    "          \",\\tTime = \", pca_time[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygLAA7vTir2O"
   },
   "source": [
    "### PCA + Annoy:\n",
    "\n",
    "- Annoy (Approximate Nearest Neighbors Oh Yeah) is a C++ library with Python bindings for searching nearest neighbors. \n",
    "- Synonymous with speed, it was released by Spotify and is used in production to serve their music recommendations.\n",
    "\n",
    "- To use annoy, install it using pip: pip3 install annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KQZbmWsXAr2L",
    "outputId": "0b86fe0c-5935-4e33-a2da-9c543d3f4526"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vDuCtHDKhp-N"
   },
   "outputs": [],
   "source": [
    "from annoy import AnnoyIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iiBBCNdeESQB"
   },
   "source": [
    "First, we build a search index with two hyperparameters - the number of dimensions of the dataset, and the number of trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WWWbPSngC_uF",
    "outputId": "a13d1f06-94d3-4608-eeeb-9b94b075a822"
   },
   "outputs": [],
   "source": [
    "# Time the indexing for Annoy\n",
    "t = AnnoyIndex(150)  # Length of item vector that will be indexed\n",
    "starttime = time.time()\n",
    "for i in range(num_images):\n",
    "    feature = feature_list_compressed[i]\n",
    "    t.add_item(i, feature)\n",
    "endtime = time.time()\n",
    "print(endtime - starttime)\n",
    "t.build(40)  # 40 trees\n",
    "t.save('data/caltech101index.ann')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eG_IYp4YDVAv"
   },
   "source": [
    "Annoy on one image:\n",
    "Now let’s find out the time it takes to search the 5 nearest neighbors of one image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "opxMx8gVHvl5"
   },
   "outputs": [],
   "source": [
    "random_image_index = 1001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XAK2m3M1DGo4",
    "outputId": "1bac427a-9208-4d57-e347-da6d953abfbd"
   },
   "outputs": [],
   "source": [
    "u = AnnoyIndex(150)\n",
    "%timeit u.get_nns_by_vector(feature_list_compressed[random_image_index], 5, include_distances=True)\n",
    "indexes = u.get_nns_by_vector(feature_list_compressed[random_image_index],\n",
    "                              5,\n",
    "                              include_distances=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jamcd0oHDLBx"
   },
   "outputs": [],
   "source": [
    "def calculate_annoy_time():\n",
    "    for i in range(0, 100):\n",
    "        indexes = u.get_nns_by_vector(feature_list_compressed[random_image_index],5,include_distances=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lkx4vOdxDRLc"
   },
   "source": [
    "Annoy on a set of images:\n",
    "\n",
    "Time the search for multiple images for Annoy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tXhEmOQhDORH",
    "outputId": "63726088-64eb-45bc-e185-3cae5005aa3d"
   },
   "outputs": [],
   "source": [
    "%time calculate_annoy_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZ7lngw5I5xl"
   },
   "source": [
    "## Conclusion:\n",
    "\n",
    "Feature extraction using RESNET50 on Caltech101 dataset:\n",
    "- Bruteforce + 2048 length feature:59.8ms\n",
    "- Bruteforce + PCA(150):5.3ms\n",
    "- Annoy + PCA(150):19us "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
